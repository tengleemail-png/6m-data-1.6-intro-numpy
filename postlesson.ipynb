{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSWZ7k05nmX0Ly1vwDyHbx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tengleemail-png/6m-data-1.6-intro-numpy/blob/main/postlesson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This post-class practice helps you reinforce the core NumPy skills we used:\n",
        "\n",
        "- Creating and inspecting arrays\n",
        "- Indexing, slicing, and boolean filtering\n",
        "- Aggregations over rows/columns\n",
        "- Reshaping and simple matrix operations\n",
        "You can work through these in the same environment you used in class (Colab or VS Code).\n",
        "\n",
        "**1. Warm-up: Rebuild the basics**\n",
        "Goal: Make array creation and inspection feel automatic.\n",
        "\n",
        "1. Create each of the following arrays and print its `shape`, `ndim`, and `dtype`:\n",
        "\n",
        " - A 1D array of integers from 10 to 19\n",
        " - A 2D array of shape `(4, 3)` filled with 1.5\n",
        " - A 3D array of zeros with shape `(2, 2, 3)`\n",
        "2. Convert the `(4, 3)` float array to integers using `.astype(int)`.\n",
        "\n",
        "3. Write down (in a markdown cell) when you would prefer `float` vs `int` in real analyst work (e.g., prices vs counts)."
      ],
      "metadata": {
        "id": "9uySQR-ppMvm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLI49TQToDUw",
        "outputId": "4601f08f-9c3c-48ab-9fb4-e740de722023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10 11 12 13 14 15 16 17 18 19] \n",
            "Shape:\n",
            " (10,) \n",
            "Dim:\n",
            " 1 \n",
            "type:\n",
            " int64\n",
            "[[1.5 1.5 1.5]\n",
            " [1.5 1.5 1.5]\n",
            " [1.5 1.5 1.5]\n",
            " [1.5 1.5 1.5]] \n",
            "Shape:\n",
            " (4, 3) \n",
            "Dim:\n",
            " 2 \n",
            "type:\n",
            " float64\n",
            "[[[0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]]] \n",
            "Shape:\n",
            " (2, 2, 3) \n",
            "Dim:\n",
            " 3 \n",
            "type:\n",
            " float64\n",
            "\n",
            " [[1 1 1]\n",
            " [1 1 1]\n",
            " [1 1 1]\n",
            " [1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "arr1d = np.arange(10,20)\n",
        "#print( arr1d, \"\\nShape:\\n\", arr1d.shape, \"\\nDim:\\n\", arr1d.ndim, \"\\ntype:\\n\", arr1d.dtype)\n",
        "\n",
        "arr2d = np.full((4,3),1.5)\n",
        "\n",
        "arr3d = np.zeros((2,2,3))\n",
        "\n",
        "print( arr1d, \"\\nShape:\\n\", arr1d.shape, \"\\nDim:\\n\", arr1d.ndim, \"\\ntype:\\n\", arr1d.dtype)\n",
        "print( arr2d, \"\\nShape:\\n\", arr2d.shape, \"\\nDim:\\n\", arr2d.ndim, \"\\ntype:\\n\", arr2d.dtype)\n",
        "print( arr3d, \"\\nShape:\\n\", arr3d.shape, \"\\nDim:\\n\", arr3d.ndim, \"\\ntype:\\n\", arr3d.dtype)\n",
        "\n",
        "\n",
        "arr2d_int = arr2d.astype(int)\n",
        "\n",
        "print(\"\\n\", arr2d_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Sales table drill: Indexing and slicing**\n",
        "\n",
        "Scenario: You have quarterly sales numbers for 4 regions (rows) over 5 quarters (columns)."
      ],
      "metadata": {
        "id": "Q3oUD_WZpZHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sales = np.array([\n",
        "    [100, 120, 110, 150, 130], # Region A\n",
        "    [90, 80, 95, 100, 110],    # Region B\n",
        "    [200, 210, 190, 220, 250], # Region C\n",
        "    [150, 140, 130, 160, 170]  # Region D\n",
        "])\n",
        "regions = np.array([\"A\", \"B\", \"C\", \"D\"])\n",
        "quarters = np.array([\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"])"
      ],
      "metadata": {
        "id": "KD4bKUuIpc79"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the following:\n",
        "\n",
        "Select all quarters for Region B as a 1D array.\n",
        "Select Q2 to Q4 (inclusive) for all regions as a 2D subarray.\n",
        "Select Q5 sales for Regions A and D only (use slicing or fancy indexing).\n",
        "Compute the shape of each result and add a brief comment: “Is this 1D or 2D, and why?”"
      ],
      "metadata": {
        "id": "CpOPjocspfB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#qn1\n",
        "reg_B = sales[1]\n",
        "\n",
        "#qn2\n",
        "q2_q4 = sales[:,1:4]\n",
        "\n",
        "#qn3\n",
        "q5_A_D = sales[[0,3], 4]\n",
        "#qn3\n",
        "q5_A_D_v2 = sales[[0,3], 4:5] # this will give you a 2D result\n",
        "\n",
        "print(\"q5_A_D id\\n\",q5_A_D, \"\\n shape:\\n\", q5_A_D.shape)\n",
        "print(\"q5_A_D id\\n\",q5_A_D_v2, \"\\n shape:\\n\", q5_A_D_v2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mknmpUN7wYVH",
        "outputId": "d39e0edb-5b78-4249-e835-027f02fa002f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q5_A_D id\n",
            " [130 170] \n",
            " shape:\n",
            " (2,)\n",
            "q5_A_D id\n",
            " [[130]\n",
            " [170]] \n",
            " shape:\n",
            " (2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Boolean masks: Work with targets**\n",
        "\n",
        "Scenario: You have campaign response data."
      ],
      "metadata": {
        "id": "Nfb3ZVi5pkW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = np.array([\"Ana\", \"Ben\", \"Chen\", \"Dana\", \"Eli\", \"Fatima\", \"George\", \"Hui\"])\n",
        "spend = np.array([200, 150, 300, 120, 180, 220, 160, 310])      # marketing spend\n",
        "revenue = np.array([400, 180, 500, 100, 220, 260, 150, 600])   # revenue\n",
        "\n"
      ],
      "metadata": {
        "id": "R8F7wDkgplUE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Compute the ROI for each person: roi = revenue / spend.\n",
        "1. Create a boolean mask for customers with roi >= 2.0.\n",
        "3. Use the mask to:\n",
        "  - List their names\n",
        "  - List their spend and revenue\n",
        "4. Create a second mask for customers with spend >= 200.\n",
        "5. Combine the two masks to find customers who have roi >= 2.0 AND spend >= 200.\n",
        "6. In a markdown cell, answer: “What business insight do you get from this filtered group?”\n"
      ],
      "metadata": {
        "id": "WRl1M_K7pnYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#qn1\n",
        "roi = revenue/spend\n",
        "print(roi)\n",
        "\n",
        "#qn2\n",
        "roi_more_2_mask = (roi >= 2.0)\n",
        "\n",
        "#qn3\n",
        "names_roi_more_2 = names[roi_more_2_mask]\n",
        "print(\"ROI more than 2:\\n\", names_roi_more_2)\n",
        "print(\"The spend is:\", spend[roi_more_2_mask], \" and the revenue is: \", revenue[roi_more_2_mask])\n",
        "\n",
        "#qn4\n",
        "spend_mask = (spend >= 200)\n",
        "\n",
        "#qn5\n",
        "print(\"Customer with roi >=2.0 and spend>=200: \", names[roi_more_2_mask & spend_mask])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PM1LvdE0mCk",
        "outputId": "3dfc3588-0b1e-405a-fe27-9988d3a9d9a7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.         1.2        1.66666667 0.83333333 1.22222222 1.18181818\n",
            " 0.9375     1.93548387]\n",
            "ROI more than 2:\n",
            " ['Ana']\n",
            "The spend is: [200]  and the revenue is:  [400]\n",
            "Customer with roi >=2.0 and spend>=200:  ['Ana']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Business Insight: Customers in the filtered group (ROI >= 2.0 AND Spend >= 200) represent our Scalable Successes. These are accounts where we spent a significant amount of money and still saw a high rate of return. We should prioritize these profiles for future budget increases."
      ],
      "metadata": {
        "id": "GkTEzgn-3eI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Gradebook: Aggregations and broadcasting**\n",
        "\n",
        "Reuse the “Gradebook” idea from class and extend it."
      ],
      "metadata": {
        "id": "s6ZgHTB9p8Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "students = np.array([\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"])\n",
        "subjects = np.array([\"Math\", \"Stats\", \"Python\"])\n",
        "\n",
        "scores = np.array([\n",
        "    [75, 80, 85],\n",
        "    [60, 65, 70],\n",
        "    [90, 88, 92],\n",
        "    [82, 79, 84],\n",
        "    [70, 72, 78]\n",
        "])"
      ],
      "metadata": {
        "id": "TXyxtNr6qELh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Compute each student’s average score (per row).\n",
        "2. Compute each subject’s average score (per column).\n",
        "3. Create `scores_centered` by subtracting the subject mean from each column (broadcasting).\n",
        "4. For `scores_centered`, compute per-student averages again.\n",
        "5. Compare which student looks best by raw average vs centered average.\n",
        "6. In a markdown cell, explain briefly why centered scores might give a fairer comparison.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jQL5nmjfqhfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#qn1\n",
        "stu_ave_score = scores.mean(axis = 1) #avg score across all sub\n",
        "\n",
        "#qn2\n",
        "sbj_ave_score = scores.mean(axis=0) #avg score per sub\n",
        "\n",
        "#qn3\n",
        "scores_centered = scores - sbj_ave_score #student score minus avg score\n",
        "\n",
        "#4\n",
        "print(\"Raw Scores:\\n\", scores)\n",
        "print(\"Raw Averages:\\n\", stu_ave_score)\n",
        "print(\"Centered Score:\\n\", scores_centered)\n",
        "print(\"Centered Averages:\\n\", scores_centered.mean(axis=1))\n",
        "# centered average will account for the difficulity of the paper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VPzsZB_3u5q",
        "outputId": "1e4b0919-4cd7-411d-f056-1ee8eecbe640"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Scores:\n",
            " [[75 80 85]\n",
            " [60 65 70]\n",
            " [90 88 92]\n",
            " [82 79 84]\n",
            " [70 72 78]]\n",
            "Raw Averages:\n",
            " [80.         65.         90.         81.66666667 73.33333333]\n",
            "Centered Score:\n",
            " [[ -0.4   3.2   3.2]\n",
            " [-15.4 -11.8 -11.8]\n",
            " [ 14.6  11.2  10.2]\n",
            " [  6.6   2.2   2.2]\n",
            " [ -5.4  -4.8  -3.8]]\n",
            "Centered Averages:\n",
            " [  2.         -13.          12.           3.66666667  -4.66666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Reshape and flatten: From daily to weekly**\n",
        "Scenario: You have 30 days of daily website visits, and you want to summarize them by week."
      ],
      "metadata": {
        "id": "Zrk11_kjrCl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_visits = np.array([\n",
        "    120, 130, 125, 140, 150,\n",
        "    160, 170, 155, 145, 135,\n",
        "    128, 132, 138, 142, 148,\n",
        "    152, 158, 162, 168, 172,\n",
        "    180, 190, 185, 175, 165,\n",
        "    155, 145, 135, 125, 115\n",
        "])"
      ],
      "metadata": {
        "id": "INCRyanGrdeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape daily_visits into a (6, 5) array representing 6 weeks × 5 days.\n",
        "Compute total visits per week.\n",
        "Compute average visits per day of the week (e.g., all “day 1 of week” together, all “day 2 of week” together, etc.).\n",
        "Flatten the reshaped array back to 1D and confirm it matches the original daily_visits.\n",
        "Hint: Pay attention to how reshaping groups the data; mention any assumptions you’re making about which days belong to which week.\n",
        "\n"
      ],
      "metadata": {
        "id": "3o-Yg17froq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Mini-project: Simple scoring model**\n",
        "This mirrors the tiny matrix multiply example from class, but with more features."
      ],
      "metadata": {
        "id": "0UEyYcQdrscM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each row: [page_views, time_on_site (minutes), past_purchases]\n",
        "X = np.array([\n",
        "    [10,  3.5,  0],\n",
        "    [25,  5.0,  1],\n",
        "    [40,  2.0,  0],\n",
        "    [15, 10.0,  3],\n",
        "    [30,  4.0,  2]\n",
        "])\n",
        "\n",
        "customers = np.array([\"C1\", \"C2\", \"C3\", \"C4\", \"C5\"])"
      ],
      "metadata": {
        "id": "jADiW304rzc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose a weight vector w = [w_views, w_time, w_purchases] (for example [0.1, 0.5, 1.0]).\n",
        "Compute a score for each customer using scores = X @ w.\n",
        "Rank customers by score (highest first).\n",
        "Change the weights to emphasize past_purchases more than other features, and recompute.\n",
        "In a markdown cell, answer:\n",
        "Which customer is top-ranked before vs after changing weights?\n",
        "In what real-world situation might you prefer each weighting?\n"
      ],
      "metadata": {
        "id": "nghQKYI6reok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "roUufvlvr3WI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Stretch ideas (optional)**\n",
        "If you’re comfortable with the above, try:\n",
        "\n",
        "Generate 1,000 random test scores with np.random.randn, scale them to have mean 70 and standard deviation 10, then:\n",
        "Clip scores to the range [0, 100]\n",
        "Compute min, max, mean, and standard deviation\n",
        "Simulate a small A/B test:\n",
        "Two groups of 20 users each\n",
        "Randomly generate conversions (0 or 1) for each group\n",
        "Compute conversion rate per group using pure NumPy operations\n"
      ],
      "metadata": {
        "id": "4amYhf_kr6SH"
      }
    }
  ]
}